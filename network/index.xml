<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>集群网络 on 腾讯云容器服务</title><link>https://book.kubetencent.io/network/</link><description>Recent content in 集群网络 on 腾讯云容器服务</description><generator>Hugo -- gohugo.io</generator><language>zh</language><atom:link href="https://book.kubetencent.io/network/index.xml" rel="self" type="application/rss+xml"/><item><title>彻底理解集群网络</title><link>https://book.kubetencent.io/network/understand-cluster-networking/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://book.kubetencent.io/network/understand-cluster-networking/</guid><description>什么是集群网络 TODO
K8S 网络模型 TODO
如何实现 K8S 集群网络 TODO
公有云 K8S 服务是如何实现集群网络的 TODO
CNI 插件 TODO
开源网络方案 TODO
参考资料 Cluster Networking: https://kubernetes.io/docs/concepts/cluster-administration/networking/</description></item><item><title>TKE 集群网络介绍</title><link>https://book.kubetencent.io/network/tke-networking/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://book.kubetencent.io/network/tke-networking/</guid><description>Global Router 方案 TODO</description></item><item><title>网络划分与最大节点/service/pod 的数量</title><link>https://book.kubetencent.io/network/analysis-cidr/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://book.kubetencent.io/network/analysis-cidr/</guid><description>创建集群时指定 CIDR 为集群网段，然后在选择 Pod数量上限/节点 和 Service数量上限/集群，最后会自动算出集群最大的节点数，这其中有计算公式。
集群网段会指定给 controller-manager 的 --cluster-cidr 参数。 选择 Service数量上限/集群 后会自动算出 service 网段，它是集群网段中的一个子网段，会将其指定給 controller-manager 的 --service-cluster-ip-range 参数。 选择 Pod数量上限/节点，即确定 PodCIDR 的掩码大小，会将其指定给 controller-manager 的 --node-cidr-mask-size 参数。 举一个例子：
/usr/bin/kube-controller-manager --cluster-cidr=10.99.0.0/19 --service-cluster-ip-range=10.99.28.0/22 --node-cidr-mask-size=24 --cluster-cidr=10.99.0.0/19 表示集群网络的 CIDR --service-cluster-ip-range=10.99.28.0/22 表示 Service 占用的子网(在TKE中是属于集群网络CIDR范围内的一个子网) TKE 默认每个节点的 CIDR 是 24 位，可以通过 kubectl describe node 查看 PodCIDR 字段来看，这里假设实际就是 24 位 此例中集群 Service 数量为：2^(32-22)=1024 个。公式：2 ^ (32 - SERVICE_CIDR_MASK_SIZE) 此例中集群节点最大数量：2^(24-19) - 2^(24-22) = 32 - 4 = 28 个 (Service占用4个节点子网段) 公式：2 ^ (POD_CIDR_MASK_SIZE - CLUSTER_CIDR_MASK_SIZE) - 2 ^ (POD_CIDR_MASK_SIZE - SERVICE_CIDR_MASK_SIZE) 此例中每个节点可以容纳 2^(32-24)=256 个 IP，减去网络地址、广播地址和子网为1的网桥 IP 地址(cbr0)，每个节点最多可以容纳 253 个 pod。但是节点 pod 实际最大容量还需要看 kubelet 启动参数 --max-pods 的值。通过 kubectl describe node 也能看到节点最大 pod 数 (Capacity.</description></item><item><title>容器路由互通</title><link>https://book.kubetencent.io/network/container-route/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://book.kubetencent.io/network/container-route/</guid><description>概述 TKE 的 POD IP 默认在整个 VPC 可路由，要在 VPC 之外访问 POD IP 可能就需要下发路由(打通)才能访问，下面罗列容器路由互通的各种情况与容器路由打通方法。
云联网容器路由互通 如果需要容器路由互通的是两个不同 VPC，并且都支持云联网，那么可以直接将你的集群开启云联网，容器路由就可以自动注册上去，跨 VPC 的容器路由就可以互通了。
集群启用云联网方法：在集群信息页点击这里开启云联网
对等连接打通的 VPC 之间容器路由互通 如果两个 VPC 是同地域的，可以自行配置 VPC 路由表，在容器的对端 VPC (要访问容器 IP VPC) 的 VPC 路由表下一跳增加容器网段下一跳，指向对应的对等连接网关即可。 如果两个 VPC 是不同地域的，除了跟上面同地域容器互通操作之外，还需要提工单或找联系售后来做路由打通操作（实际就是下发容器路由给对等连接网关）。若有已创建的 TKE 集群，请提供集群id与对等连接id(pcx-开头)，否则提供：对等连接id、容器所在地域、vpcid (vpc-开头) 与容器网段。 专线打通的网络之间容器路由互通 如果您的 IDC 或办公网通过专线与腾讯云 VPC 打通，并且想要跟腾讯云 VPC 里的 TKE 容器路由互通，需要提工单或找联系售后来做路由打通操作（实际就是下发容器路由给专线网关）。
若有已创建的 TKE 集群，请提供集群id与专线网关id(pcg-开头)，否则提供对等连接id、容器所在地域、vpcid (vpc-开头) 、容器网段与专线网关id。如果您的 IDC 或办公网的网络是 BGP 的，可以自动学习容器路由，待容器路由打通之后，即可正常访问容器 IP，如果不是 BGP 则需要配置路由，容器网段下一跳到专线网关。
注意 路由打通之后，可以修改下集群中 ip-masq-agent 的配置来优化下:
kubectl -n kube-system edit configmap ip-masq-agent-config nonMasqueradeCIDRs 加上容器对端网络的网段，这样可以让从容器里主动请求对端网络的 IP 不做 SNAT，因为路由已经通了，出 VPC 的包就可以不用 SNAT，减少性能损耗。</description></item></channel></rss>